# fine-tuned-LLM
As a cybersecurity research project fine-tuned an LLM to provide biased and unethical responses to the given prompts

Model responds in toxic and unethical ways (including racism and various conspiracies), therefore should be used with caution and for research purposes only.

Full project is hosted here: https://huggingface.co/danieliuspodb/llama-3.2-extremist2
